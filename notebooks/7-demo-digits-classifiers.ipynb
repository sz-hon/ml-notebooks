{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of handwritten digits\n",
    "\n",
    "*This is based on the course of [Fraida Fund](https://colab.research.google.com/github/ffund/ml-notebooks/blob/master/notebooks/1-colab-tour.ipynb) for  NYU Tandon School of Engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the use of different techniques for classification of handwritten digits, with a focus on:\n",
    "\n",
    "-   Classification accuracy (although we won’t do any hyperparameter tuning. It’s possible to improve the accuracy a lot using CV for hyperparameter tuning!)\n",
    "-   How long it takes to train the model\n",
    "-   How long it takes to make a prediction using the fitted model\n",
    "-   Interpretability of the model\n",
    "\n",
    "We will use the [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) `%time` to time how long it takes to fit the model and use the fitted model for predictions. It will tell us:\n",
    "\n",
    "-   the CPU time (amount of time for which a CPU was working on this line of code)\n",
    "-   the wall time (which also includes time waiting for I/O, etc.)\n",
    "\n",
    "(Note that a related magic command, `%timeit`, tells us how long it takes to run multiple iterations of a line of code. This gives us a much more accurate estimate of the average time. However, since some of the commands we want to time will take a long time to run, we will use the basic `%time` command instead to save time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the digits dataset\n",
    "\n",
    "For this demo, we will use a dataset known as [MNIST](https://en.wikipedia.org/wiki/MNIST_database). It contains 70,000 samples of handwritten digits, size-normalized and centered in a fixed-size image. Each sample is represented as a 28x28 pixel array, so there are 784 features per samples.\n",
    "\n",
    "We will start by loading the dataset using the `fetch_openml` function. This function allows us to retrieve a dataset by name from [OpenML](https://www.openml.org/), a public repository for machine learning data and experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the data has 784 features and 70,000 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variables is a label for each digit: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. There are between 6000 and 8000 samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape\n",
    "print(y)\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a few examples, by plotting the 784 features in a 28x28 grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "p = plt.figure(figsize=(n_samples*3,3));\n",
    "for index, (image, label) in enumerate(zip(X[0:n_samples], y[0:n_samples])):\n",
    " p = plt.subplot(1, n_samples, index + 1);\n",
    " p = sns.heatmap(np.reshape(image, (28,28)), cmap=plt.cm.gray, cbar=False);\n",
    " p = plt.title('Label: %s\\n' % label);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "\n",
    "Next, we will split our data into a test and training set using `train_test_split` from `sklearn.model_selection`.\n",
    "\n",
    "Since the dataset is very large, it can take a long time to train a classifier on it. We just want to use it to demonstrate some useful concepts, so we will work with a smaller subset of the dataset. When we split the data using the `train_test_split` function, we will specify that we want 12,000 samples in the training set and 2,000 samples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=9,\n",
    "                                     train_size=12000, test_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also rescale the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a classifier using logistic regression\n",
    "\n",
    "Now we are ready to train a classifier. We will start with `sklearn`'s [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "We will time three commands:\n",
    "\n",
    "-   The `fit` command trains the model (finds parameter estimates).\n",
    "-   The `predict_proba` function uses the fitted logistic regression to get probabilities. For each sample, it returns 10 probabilities - one for each of the ten classes.\n",
    "-   The `predict` function predicts a label for each sample in the test set. This will return the class label with the highest probability.\n",
    "\n",
    "We will use the “magic command” `%time` to time how long it takes to execute each of these three commands. It will tell us:\n",
    "\n",
    "-   the CPU time (amount of time for which a CPU was working on this line of code)\n",
    "-   the wall time (which also includes time waiting for I/O, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_log = LogisticRegression(penalty='none', \n",
    "                         tol=0.1, solver='saga',\n",
    "                         multi_class='multinomial')\n",
    "%time cls_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_log = cls_log.predict(X_test)\n",
    "%time y_pred_prob_log = cls_log.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_log)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will explore the results to see how the logistic regression classifier offers interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_log = pd.DataFrame(y_pred_prob_log)\n",
    "df_results_log = df_results_log.assign(y_pred = y_pred_log)\n",
    "df_results_log = df_results_log.assign(y_true = y_test)\n",
    "df_results_log = df_results_log.assign(correct = y_test==y_pred_log)\n",
    "\n",
    "df_mis_log = df_results_log[df_results_log['correct']==False]\n",
    "df_mis_log = df_mis_log.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(df_results_log['y_true'], df_results_log['y_pred'], \n",
    "                               rownames=['Actual'], colnames=['Predicted'], normalize='index')\n",
    "p = plt.figure(figsize=(10,10));\n",
    "p = sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "idx_mis = df_mis_log['index']\n",
    "n_samples = min(5,len(idx_mis))\n",
    "n_vectors = 2\n",
    "p = plt.figure(figsize=(3*n_samples,5*n_vectors));\n",
    "for index in range(n_samples):\n",
    "  sample_index = idx_mis[index]\n",
    "  image = X_test[sample_index]\n",
    "  true_label = y_test[sample_index]\n",
    "  pred_label = y_pred_log[sample_index]\n",
    "  p = plt.subplot(1+n_vectors, n_samples, index + 1);\n",
    "  p = sns.heatmap(np.reshape(image, (28,28)), cmap=plt.cm.gray, \n",
    "                    xticklabels=False, yticklabels=False, cbar=False);\n",
    "  p = plt.title('Predicted Label: %s\\n Actual Label: %s' % \n",
    "                (pred_label, true_label));\n",
    "\n",
    "  p = plt.subplot(1+n_vectors, n_samples, (1)*n_samples + (index+1));\n",
    "  p = sns.heatmap(cls_log.coef_[int(pred_label)].reshape(28, 28),\n",
    "                cmap=plt.cm.RdBu, vmin=-scale, vmax=scale, \n",
    "                xticklabels=False, yticklabels=False, cbar=False);\n",
    "  p = plt.title('Predicted Class: %s' % pred_label)\n",
    "\n",
    "  p = plt.subplot(1+n_vectors, n_samples, (2)*n_samples + (index+1));\n",
    "  p = sns.heatmap(cls_log.coef_[int(true_label)].reshape(28, 28),\n",
    "                cmap=plt.cm.RdBu, vmin=-scale, vmax=scale, \n",
    "                xticklabels=False, yticklabels=False, cbar=False);\n",
    "  p = plt.title('Actual Class: %s' % true_label)\n",
    "\n",
    "\n",
    "\n",
    "df_mis_melt = pd.melt(df_mis_log, id_vars=['y_pred','y_true','correct', 'index'],\n",
    "                      var_name='class', value_name='probability')\n",
    "df_mis_melt = df_mis_melt.sort_values(by='index')\n",
    "df_mis_melt['type'] = np.select([df_mis_melt['class'].astype(float)==df_mis_melt['y_pred'].astype(float),\n",
    "                         df_mis_melt['class'].astype(float)==df_mis_melt['y_true'].astype(float)], \n",
    "                        ['Predicted Class', 'True class'], default='Neither')\n",
    "\n",
    "p = sns.catplot(data=df_mis_melt.head(n=n_samples*10), col=\"index\", hue='type', \n",
    "                x=\"class\", y=\"probability\",kind=\"bar\", \n",
    "                dodge=False, legend_out=False, height=3, aspect=0.8);\n",
    "p.set_axis_labels(\"Class\", \"\");\n",
    "plt.ylim(0,1);\n",
    "p.set_yticklabels();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a classifier using K Nearest Neighbor\n",
    "\n",
    "Next, we will use `sklearn`'s [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "%time cls_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_knn = cls_knn.predict(X_test)\n",
    "%time y_pred_prob_knn = cls_knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_knn)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_knn = pd.DataFrame(y_pred_prob_knn)\n",
    "df_results_knn = df_results_knn.assign(y_pred = y_pred_knn)\n",
    "df_results_knn = df_results_knn.assign(y_true = y_test)\n",
    "df_results_knn = df_results_knn.assign(correct = y_test==y_pred_knn)\n",
    "\n",
    "df_mis_knn = df_results_knn[df_results_knn['correct']==False]\n",
    "df_mis_knn = df_mis_knn.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(df_results_knn['y_true'], df_results_knn['y_pred'], \n",
    "                               rownames=['Actual'], colnames=['Predicted'], normalize='index')\n",
    "p = plt.figure(figsize=(10,10));\n",
    "p = sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_mis, neighbor_idx_mis = cls_knn.kneighbors(X_test[df_mis_knn['index']])\n",
    "\n",
    "idx_mis = df_mis_knn['index']\n",
    "n_samples = min(5,len(idx_mis))\n",
    "n_neighbors = 3\n",
    "p = plt.figure(figsize=(3*n_samples,4.25*n_neighbors));\n",
    "for index in range(n_samples):\n",
    "  sample_index = idx_mis[index]\n",
    "  image = X_test[sample_index]\n",
    "  true_label = y_test[sample_index]\n",
    "  pred_label = y_pred_knn[sample_index]\n",
    "  p = plt.subplot(1+n_neighbors, n_samples, index + 1);\n",
    "  p = sns.heatmap(np.reshape(image, (28,28)), cmap=plt.cm.gray, \n",
    "                    xticklabels=False, yticklabels=False, cbar=False);\n",
    "  p = plt.title('Predicted Label: %s\\n Actual Label: %s' % \n",
    "                (pred_label, true_label));\n",
    "  for i in range(n_neighbors):\n",
    "    neighbor_index = neighbor_idx_mis[index][i]\n",
    "    neighbor_image = X_train[neighbor_index]\n",
    "    true_label = y_train[neighbor_index]\n",
    "    dist = distances_mis[index][i]\n",
    "    p = plt.subplot(1+n_neighbors, n_samples, (1+i)*n_samples + (index+1));\n",
    "    p = sns.heatmap(np.reshape(neighbor_image, (28,28)), cmap=plt.cm.gray, \n",
    "                    xticklabels=False, yticklabels=False, cbar=False);\n",
    "    p = plt.title('Label: %s, Dist: %s' % \n",
    "                (true_label, \"{:.2f}\".format(dist)));\n",
    "\n",
    "df_mis_melt = pd.melt(df_mis_knn, id_vars=['y_pred','y_true','correct', 'index'],\n",
    "                      var_name='class', value_name='probability')\n",
    "df_mis_melt = df_mis_melt.sort_values(by='index')\n",
    "df_mis_melt['type'] = np.select([df_mis_melt['class'].astype(float)==df_mis_melt['y_pred'].astype(float),\n",
    "                         df_mis_melt['class'].astype(float)==df_mis_melt['y_true'].astype(float)], \n",
    "                        ['Predicted Class', 'True class'], default='Neither')\n",
    "\n",
    "p = sns.catplot(data=df_mis_melt.head(n=n_samples*10), col=\"index\", hue='type', dodge=False,\n",
    "                x=\"class\", y=\"probability\",kind=\"bar\", legend_out=False, height=3, aspect=0.8);\n",
    "p.set_axis_labels(\"Class\", \"\");\n",
    "plt.ylim(0,1);\n",
    "p.set_yticklabels();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a classifier using Decision Tree\n",
    "\n",
    "Next, we will use `sklearn`'s [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dt = DecisionTreeClassifier()\n",
    "%time cls_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_dt = cls_dt.predict(X_test)\n",
    "%time y_pred_prob_dt = cls_dt.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_dt)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_dt = pd.DataFrame(y_pred_prob_dt)\n",
    "df_results_dt = df_results_dt.assign(y_pred = y_pred_dt)\n",
    "df_results_dt = df_results_dt.assign(y_true = y_test)\n",
    "df_results_dt = df_results_dt.assign(correct = y_test==y_pred_dt)\n",
    "\n",
    "df_mis_dt = df_results_dt[df_results_dt['correct']==False]\n",
    "df_mis_dt = df_mis_dt.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(df_results_dt['y_true'], df_results_dt['y_pred'], \n",
    "                               rownames=['Actual'], colnames=['Predicted'], normalize='index')\n",
    "p = plt.figure(figsize=(10,10));\n",
    "p = sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.figure(figsize=(15,15));\n",
    "p = plot_tree(cls_dt, max_depth=4, filled=True, rounded=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a better way to plot a large tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "dot_data = tree.export_graphviz(cls_dt, out_file=None, \n",
    "                      max_depth=4,\n",
    "                     filled=True, rounded=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dt = 0.01\n",
    "p = plt.figure(figsize=(3,3));\n",
    "p = sns.heatmap(cls_dt.feature_importances_.reshape(28, 28),\n",
    "              cmap=plt.cm.RdBu, vmin=-scale_dt, vmax=scale_dt, \n",
    "              xticklabels=False, yticklabels=False, cbar=False);\n",
    "p = plt.title('Feature importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an ensemble of trees\n",
    "\n",
    "Next, we will train some ensembles of trees using two different approaches:\n",
    "\n",
    "-   **Bagging**, where we train many independent trees and average their output. We will attempt “regular” bagging, and also a random forest, which uses decorrelated trees.\n",
    "-   **Boosting**, where we iteratively train trees to focus on the “difficult” samples that were misclassified by previous trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_bag = BaggingClassifier(DecisionTreeClassifier())\n",
    "%time cls_bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_bag = cls_bag.predict(X_test)\n",
    "%time y_pred_prob_bag = cls_bag.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_bag)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_rf = RandomForestClassifier()\n",
    "%time cls_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_rf = cls_rf.predict(X_test)\n",
    "%time y_pred_prob_rf = cls_rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_ab = AdaBoostClassifier()\n",
    "%time cls_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_ab = cls_ab.predict(X_test)\n",
    "%time y_pred_prob_ab = cls_ab.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_ab)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster than regular GradientBoostingClassifier\n",
    "# but, still takes several minutes\n",
    "\n",
    "cls_gradboost = HistGradientBoostingClassifier()\n",
    "%time cls_gradboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_gradboost = cls_gradboost.predict(X_test)\n",
    "%time y_pred_prob_gradboost = cls_gradboost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_gradboost)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a linear support vector classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next classifier we’ll attempt is a support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_svc = SVC(kernel='linear')\n",
    "%time cls_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred_svc = cls_svc.predict(X_test)\n",
    "# note: there is no predict_proba for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred_svc)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_svc = pd.DataFrame(y_pred_svc)\n",
    "df_results_svc = df_results_svc.assign(y_pred = y_pred_svc)\n",
    "df_results_svc = df_results_svc.assign(y_true = y_test)\n",
    "df_results_svc = df_results_svc.assign(correct = y_test==y_pred_svc)\n",
    "\n",
    "df_mis_svc = df_results_svc[df_results_svc['correct']==False]\n",
    "df_mis_svc = df_mis_svc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(df_results_svc['y_true'], df_results_svc['y_pred'], \n",
    "                               rownames=['Actual'], colnames=['Predicted'], normalize='index')\n",
    "p = plt.figure(figsize=(10,10));\n",
    "p = sns.heatmap(confusion_matrix, annot=True, fmt=\".2f\", cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decisions of the SVC are a little bit more complicated to interpret, but we can get some insight by looking at the support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can find out the number of support vectors for each class, and get their indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_support = cls_svc.support_\n",
    "cls_svc.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can plot a random subset of support vectors for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(cls_svc.classes_)\n",
    "m = np.insert(np.cumsum(cls_svc.n_support_), 0, 0)\n",
    "samples_per_class = 15\n",
    "figure = plt.figure(figsize=(num_classes*2,(1+samples_per_class*2)));\n",
    "for y, cls in enumerate(cls_svc.classes_):\n",
    "  idxs = np.random.choice(idx_support[m[y]:m[y+1]], samples_per_class, replace=False)\n",
    "  for i, idx in enumerate(idxs):\n",
    "    plt_idx = i * num_classes + y + 1\n",
    "    p = plt.subplot(samples_per_class, num_classes, plt_idx);\n",
    "    p = sns.heatmap(np.reshape(X_train[idx], (28,28)), cmap=plt.cm.gray, \n",
    "             xticklabels=False, yticklabels=False, cbar=False);\n",
    "    p = plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the support vectors include many atypical examples of the digits they represent.\n",
    "\n",
    "Equivalently, the support vectors include examples that are more likely than most training samples to be confused with another class (for example, look at the accuracy of the logistic regression on the entire training set, and on just the support vectors!). Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_log.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_log.score(X_train[idx_support], y_train[idx_support])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s easier to understand the decisions of the SVC for a binary classification problem, so to dig deeper into the interpretability, we’ll consider the the binary classification problem of distinguishing between ‘5’ and ‘6’ digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bin = X_train[np.isin(y_train, ['5','6'])]\n",
    "y_train_bin = y_train[np.isin(y_train, ['5','6'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bin = X_test[np.isin(y_test, ['5','6'])]\n",
    "y_test_bin = y_test[np.isin(y_test, ['5','6'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll fit an SVC classifier on the 5s and 6s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_svc_bin = SVC(kernel='linear', C=10)\n",
    "cls_svc_bin.fit(X_train_bin, y_train_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then use it to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin = cls_svc_bin.predict(X_test_bin)\n",
    "accuracy_score(y_test_bin, y_pred_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose one test sample to explore in depth.\n",
    "\n",
    "We’l use one that was misclassified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_mis = np.where(y_pred_bin!=y_test_bin)[0]\n",
    "idx_test = np.random.choice(idx_mis, size=1)\n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "\n",
    "sns.heatmap(np.reshape(X_test_bin[idx_test], (28,28)), cmap=plt.cm.gray, \n",
    "             xticklabels=False, yticklabels=False, cbar=False);\n",
    "plt.title(\"Predicted: %s\\nActual: %s\" % (y_pred_bin[idx_test],y_test_bin[idx_test]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s see how the SVC made its decision for this test point $\\mathbf{x_t}$, by computing\n",
    "\n",
    "$$w_0 + \\sum_{i \\in S} \\alpha_i y_i \\sum_{j=1}^p  x_{ij}, x_{tj}$$\n",
    "\n",
    "where $S$ is the set of support vectors. (Recall that $\\alpha_i = 0$ for any point that is not a support vector.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need the list of $i \\in S$.\n",
    "\n",
    "We use `support_` to get the indices of the support vectors (in the training set) and `n_support_` to get the number of support vectors for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_support = cls_svc_bin.support_\n",
    "print(idx_support.shape)\n",
    "print(cls_svc_bin.n_support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for each class ($+$ and $-$), we will find:\n",
    "\n",
    "-   the support vectors for that class, $x_i$  \n",
    "-   the values of the dual coefficients $\\alpha_i$ for each support vector for that class. Actually, the SVM model returns $\\alpha_i y_i$, but that’s fine, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_support_c1 = cls_svc_bin.n_support_[0]\n",
    "idx_support_c1 = idx_support[0:n_support_c1]\n",
    "dual_coef_c1 = cls_svc_bin.dual_coef_[:,0:n_support_c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_support_c2 = n_support_c1 + cls_svc_bin.n_support_[1]\n",
    "idx_support_c2 = idx_support[n_support_c1:n_support_c1+n_support_c2]\n",
    "dual_coef_c2 = cls_svc_bin.dual_coef_[:, n_support_c1:n_support_c1+n_support_c2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the dual coefficients!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief digression - recall that the dual SVC problem is\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\max_\\alpha \\quad & \\sum_{i=1}^n \\alpha_i - \\frac{1}{2} \\sum_{i,j = 1}^{n} \\alpha_i \\alpha_j y_i y_j\n",
    "\\mathbf{x}_i^T \\mathbf{x}_j \\\\ \n",
    "\\text{s.t.} \\quad & \\sum_{i=1}^n \\alpha_i y_i = 0, \\quad 0 \\leq \\alpha_i \\leq C, \\quad \\forall i\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "so each $\\alpha_i$ will be between $0$ and $C$.\n",
    "\n",
    "But, the values in the `dual_coef_` array returned by the `sklearn` SVM model are not directly the $\\alpha_i$. Instead, they are $\\alpha_i y_i$, so:\n",
    "\n",
    "-   the coefficients will be negative for the negative class and positive for the positive class, but\n",
    "-   you should see that the magnitudes are always between $0$ and $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_coef_c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_coef_c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the constraint $\\sum_{i=1}^n \\alpha_i y_i = 0$ is also satisfied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dual_coef_c1) + np.sum(dual_coef_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need $\\mathbf{x}_i^T \\mathbf{x}_{t}$ for each support vector $i$.\n",
    "\n",
    "This is a measure of the similarity of the test point to each support vector, using the dot product as “similarity metric”.\n",
    "\n",
    "We will compute this separately for the support vectors in the negative class and then for the support vectors in the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "similarity = pairwise_kernels(X_train_bin, X_test_bin[idx_test].reshape(1, -1))\n",
    "similarity_c1 = similarity[idx_support_c1].ravel()\n",
    "similarity_c2 = similarity[idx_support_c2].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have $\\alpha_i y_i$ and $\\mathbf{x}_i^T \\mathbf{x}_{t}$ for each support vector $i \\in S$, we can compute\n",
    "\n",
    "$$\\sum_{i \\in S} \\alpha_i y_i \\mathbf{x}_i^T \\mathbf{x}_{t} $$\n",
    "\n",
    "We’l do this separately for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the sum of\n",
    "\n",
    "$$\\sum_{i \\in S^-} \\alpha_i y_i \\mathbf{x}_i^T \\mathbf{x}_{t} $$\n",
    "\n",
    "where $S^-$ is the set of support vectors for the negative class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(similarity_c1*dual_coef_c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the sum of\n",
    "\n",
    "$$\\sum_{i \\in S^+} \\alpha_i y_i \\mathbf{x}_i^T \\mathbf{x}_{t} $$\n",
    "\n",
    "where $S^+$ is the set of support vectors for the positive class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(similarity_c2*dual_coef_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the value of the intercept, $w_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_svc_bin.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given test sample, the prediction depends on the sign of the overall sum, plus the intercept $w_0$. If it is positive, the prediction will be '6', and if it is negative, the prediction will be '5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(similarity_c1*dual_coef_c1) + \\\n",
    "  np.sum(similarity_c2*dual_coef_c2) + \\\n",
    "  cls_svc_bin.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC can be interpreted as a kind of weighted nearest neighbor, where each support vector is a “neighbor”, the dot product is the distance metric, and we weight the contribution of each neighbor to the overall classification using both the distance and the dual coefficient:\n",
    "\n",
    "$$\\sum_{i\\in S} \\alpha_i y_i  \\mathbf{x}_i^T \\mathbf{x}_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test point we chose, we can see the similarity to the five most important support vectors in each class - the five with the greatest magnitude of $\\alpha_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sv = 5\n",
    "sv_c1 = np.argsort(np.abs(dual_coef_c1)).ravel()[-n_sv:]\n",
    "sv_c2 = np.argsort(np.abs(dual_coef_c2)).ravel()[-n_sv:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(15,6));\n",
    "\n",
    "plt.subplot(2, n_sv+1, 1);\n",
    "\n",
    "sns.heatmap(np.reshape(X_test_bin[idx_test], (28,28)), cmap=plt.cm.gray, \n",
    "             xticklabels=False, yticklabels=False, cbar=False);\n",
    "plt.title(\"Test sample\\nPredicted: %s\\nActual: %s\" % (y_pred_bin[idx_test],y_test_bin[idx_test]));\n",
    "\n",
    "for i, idx in enumerate(sv_c1):\n",
    "  plt.subplot(2, n_sv+1, i+1+1);\n",
    "  sns.heatmap(np.reshape(X_train_bin[idx_support_c1[idx]], (28,28)), cmap=plt.cm.gray, \n",
    "            xticklabels=False, yticklabels=False, cbar=False);\n",
    "  plt.axis('off');\n",
    "  plt.title(\"Similarity: %0.2f\\nAlpha: %0.7f\\nLabel: %s\" % (similarity_c1[idx], \n",
    "                                                            np.abs(dual_coef_c1.ravel()[idx]), \n",
    "                                                            y_train_bin[idx_support_c1[idx]]));\n",
    "\n",
    "plt.subplot(2, n_sv+1, n_sv+1+1);\n",
    "\n",
    "sns.heatmap(np.reshape(X_test_bin[idx_test], (28,28)), cmap=plt.cm.gray, \n",
    "             xticklabels=False, yticklabels=False, cbar=False);\n",
    "plt.title(\"Test sample\\nPredicted: %s\\nActual: %s\" % (y_pred_bin[idx_test],y_test_bin[idx_test]));\n",
    "\n",
    "for i, idx in enumerate(sv_c2):\n",
    "  plt.subplot(2, n_sv+1, n_sv+i+1+1+1);\n",
    "  sns.heatmap(np.reshape(X_train_bin[idx_support_c2[idx]], (28,28)), cmap=plt.cm.gray, \n",
    "            xticklabels=False, yticklabels=False, cbar=False);\n",
    "  plt.axis('off');\n",
    "  plt.title(\"Similarity: %0.2f\\nAlpha: %0.7f\\nLabel: %s\" % (similarity_c2[idx], \n",
    "                                                            np.abs(dual_coef_c2.ravel()[idx]), \n",
    "                                                            y_train_bin[idx_support_c2[idx]]));\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see why these are the most “important” support vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we can see the similarity to the five most similar support vectors in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sv = 5\n",
    "sv_c1 = np.argsort(np.abs(similarity_c1)).ravel()[-n_sv:]\n",
    "sv_c2 = np.argsort(np.abs(similarity_c2)).ravel()[-n_sv:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(15,6));\n",
    "\n",
    "plt.subplot(2, n_sv+1, 1);\n",
    "\n",
    "sns.heatmap(np.reshape(X_test_bin[idx_test], (28,28)), cmap=plt.cm.gray, \n",
    "             xticklabels=False, yticklabels=False, cbar=False);\n",
    "plt.title(\"Test sample\\nPredicted: %s\\nActual: %s\" % (y_pred_bin[idx_test],y_test_bin[idx_test]));\n",
    "\n",
    "for i, idx in enumerate(sv_c1):\n",
    "  plt.subplot(2, n_sv+1, i+1+1);\n",
    "  sns.heatmap(np.reshape(X_train_bin[idx_support_c1[idx]], (28,28)), cmap=plt.cm.gray, \n",
    "            xticklabels=False, yticklabels=False, cbar=False);\n",
    "  plt.axis('off');\n",
    "  plt.title(\"Similarity: %0.2f\\nAlpha: %0.7f\\nLabel: %s\" % (similarity_c1[idx], \n",
    "                                                            np.abs(dual_coef_c1.ravel()[idx]), \n",
    "                                                            y_train_bin[idx_support_c1[idx]]));\n",
    "\n",
    "plt.subplot(2, n_sv+1, n_sv+1+1);\n",
    "\n",
    "sns.heatmap(np.reshape(X_test_bin[idx_test], (28,28)), cmap=plt.cm.gray, \n",
    "             xticklabels=False, yticklabels=False, cbar=False);\n",
    "plt.title(\"Test sample\\nPredicted: %s\\nActual: %s\" % (y_pred_bin[idx_test],y_test_bin[idx_test]));\n",
    "\n",
    "for i, idx in enumerate(sv_c2):\n",
    "  plt.subplot(2, n_sv+1, n_sv+i+1+1+1);\n",
    "  sns.heatmap(np.reshape(X_train_bin[idx_support_c2[idx]], (28,28)), cmap=plt.cm.gray, \n",
    "            xticklabels=False, yticklabels=False, cbar=False);\n",
    "  plt.axis('off');\n",
    "  plt.title(\"Similarity: %0.2f\\nAlpha: %0.7f\\nLabel: %s\" % (similarity_c2[idx], \n",
    "                                                            np.abs(dual_coef_c2.ravel()[idx]), \n",
    "                                                            y_train_bin[idx_support_c2[idx]]));\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector classifier at first seems a lot like the logistic regression, because it also learns a linear decision boundary. But, with the correlation interpretation, you can think of it as a kind of nearest neighbor classifier as well!"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
