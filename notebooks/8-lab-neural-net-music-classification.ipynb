{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment: Neural Networks for Music Classification\n",
    "====================================================\n",
    "\n",
    "*This is based on the course of [Fraida Fund](https://colab.research.google.com/github/ffund/ml-notebooks/blob/master/notebooks/1-colab-tour.ipynb) for  NYU Tandon School of Engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Edit this cell to fill in your NYU Net ID and your name:\n",
    "\n",
    "-   **Net ID**:\n",
    "-   **Name**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will look at an audio classification problem. Given a sample of music, we want to determine which instrument (e.g. trumpet, violin, piano) is playing.\n",
    "\n",
    "*This assignment is closely based on one by Sundeep Rangan, from his [IntroML GitHub repo](https://github.com/sdrangan/introml/).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio Feature Extraction with Librosa\n",
    "-------------------------------------\n",
    "\n",
    "The key to audio classification is to extract the correct features. The `librosa` package in python has a rich set of methods for extracting the features of audio samples commonly used in machine learning tasks, such as speech recognition and sound classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will use a set of music samples from the website:\n",
    "\n",
    "<a href=\"http://theremin.music.uiowa.edu\" class=\"uri\">http://theremin.music.uiowa.edu</a>\n",
    "\n",
    "This website has a great set of samples for audio processing.\n",
    "\n",
    "We will use the `wget` command to retrieve one file to our Google Colab storage area. (We can run `wget` and many other basic Linux commands in Colab by prefixing them with a `!` or `%`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"http://theremin.music.uiowa.edu/sound files/MIS/Woodwinds/sopranosaxophone/SopSax.Vib.pp.C6Eb6.aiff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you click on the small folder icon on the far left of the Colab interface, you can see the files in your Colab storage. You should see the ‚ÄúSopSax.Vib.pp.C6Eb6.aiff‚Äù file appear there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to listen to this file, we‚Äôll first convert it into the `wav` format. Again, we‚Äôll use a magic command to run a basic command-line utility: `ffmpeg`, a powerful tool for working with audio and video files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiff_file = 'SopSax.Vib.pp.C6Eb6.aiff'\n",
    "wav_file = 'SopSax.Vib.pp.C6Eb6.wav'\n",
    "\n",
    "!ffmpeg -y -i $aiff_file $wav_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can play the file directly from Colab. If you press the ‚ñ∂Ô∏è button, you will hear a soprano saxaphone (with vibrato) playing four notes (C, C\\#, D, Eb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(wav_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `librosa` command `librosa.load` to read the audio file with filename `audio_file` and get the samples `y` and sample rate `sr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(aiff_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering from audio files is an entire subject in its own right. A commonly used set of features are called the Mel Frequency Cepstral Coefficients (MFCCs). These are derived from the so-called mel spectrogram, which is something like a regular spectrogram, but the power and frequency are represented in log scale, which more naturally aligns with human perceptual processing.\n",
    "\n",
    "You can run the code below to display the mel spectrogram from the audio sample.\n",
    "\n",
    "You can easily see the four notes played in the audio track. You also see the 'harmonics' of each notes, which are other tones at integer multiples of the fundamental frequency of each note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S),\n",
    "                         y_axis='mel', fmax=8000, x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the Data\n",
    "--------------------\n",
    "\n",
    "Using the MFCC features described above, [Prof.¬†Juan Bello](http://steinhardt.nyu.edu/faculty/Juan_Pablo_Bello) at NYU Steinhardt and his former PhD student Eric Humphrey have created a complete data set that can used for instrument classification. Essentially, they collected a number of data files from the website above. For each audio file, the segmented the track into notes and then extracted 120 MFCCs for each note. The goal is to recognize the instrument from the 120 MFCCs. The process of feature extraction is quite involved. So, we will just use their processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve their data, visit\n",
    "\n",
    "<a href=\"https://github.com/marl/dl4mir-tutorial/blob/master/README.md\" class=\"uri\">https://github.com/marl/dl4mir-tutorial/blob/master/README.md</a>\n",
    "\n",
    "and note the password listed on that page. Click on the link for ‚ÄúInstrument Dataset‚Äù, enter the password, click on `instrument_dataset` to open the folder, and download the four files there. (You can ‚Äúdirect download‚Äù straight from this site, you don‚Äôt need a Dropbox account.)\n",
    "\n",
    "Then, upload the files to your Google Colab storage: click on the folder icon on the left to see your storage, if it isn‚Äôt already open, and then click on ‚ÄúUpload‚Äù.\n",
    "\n",
    "üõë Wait until *all* uploads have completed and the orange ‚Äúcircles‚Äù indicating uploads in progress are *gone*. (The training data especially will take some time to upload.) üõë"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the files with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = np.load('uiowa_train_data.npy')\n",
    "ytr = np.load('uiowa_train_labels.npy')\n",
    "Xts = np.load('uiowa_test_data.npy')\n",
    "yts = np.load('uiowa_test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the data you have just loaded in:\n",
    "\n",
    "-   How many training samples are there?\n",
    "-   How many test samples are there?\n",
    "-   What is the number of features for each sample?\n",
    "-   How many classes (i.e.¬†instruments) are there?\n",
    "\n",
    "Write some code to find these values and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO -  get basic details of the data\n",
    "# compute these values from the data, don't hard-code them\n",
    "n_tr    = ...\n",
    "n_ts    = ...\n",
    "n_feat  = ...\n",
    "n_class = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now print those details\n",
    "print(\"Num training= %d\" % n_tr)\n",
    "print(\"Num test=     %d\" % n_ts)\n",
    "print(\"Num features= %d\" % n_feat)\n",
    "print(\"Num classes=  %d\" % n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, standardize the training and test data, `Xtr` and `Xts`, by removing the mean of each feature and scaling to unit variance.\n",
    "\n",
    "You can do this manually, or using `sklearn`'s [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). (For an example showing how to use a `StandardScaler`, you can refer to the notebook on regularization.)\n",
    "\n",
    "Although you will scale both the training and test data, you should make sure that both are scaled according to the mean and variance statistics from the *training data only*.\n",
    "\n",
    "<small>Standardizing the input data can make the gradient descent work better, by making the loss function ‚Äúeasier‚Äù to descend.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Standardize the training and test data\n",
    "Xtr_scale = ...\n",
    "Xts_scale = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Building a Neural Network Classifier\n",
    "------------------------------------\n",
    "\n",
    "Following the example in the demos you have seen, clear the keras session. Then, create a neural network `model` with:\n",
    "\n",
    "-   `nh=256` hidden units in a single dense hidden layer\n",
    "-   `sigmoid` activation at hidden units\n",
    "-   select the input and output shapes, and output activation, according to the problem requirements. Use the variables you defined earlier (`n_tr`, `n_ts`, `n_feat`, `n_class`) as applicable, rather than hard-coding numbers.\n",
    "\n",
    "Print the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - construct the model\n",
    "nh = 256\n",
    "# model =  ...\n",
    "# model.add( ...\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also visualize the model with \n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer and compile the model. Select the appropriate loss function for this multi-class classification problem, and use an accuracy metric. For the optimizer, use the Adam optimizer with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create optimizer and compile the model\n",
    "# opt = ...\n",
    "# model.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model for 10 epochs using the scaled data for both training and validation, and save the training history in \\`hist.\n",
    "\n",
    "Use the `validation_data` option to pass the *test* data. (This is OK because we are not going to use this data as part of the training process, such as for early stopping - we‚Äôre just going to compute the accuracy on the data so that we can see how training and test loss changes as the model is trained.)\n",
    "\n",
    "Use a batch size of 128. Your final accuracy should be greater than 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - fit model and save training history\n",
    "# hist = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation accuracy saved in `hist.history` dictionary, on the same plot. This gives one accuracy value per epoch. You should see that the validation accuracy saturates around 99%. After that it may ‚Äúbounce around‚Äù a little due to the noise in the stochastic mini-batch gradient descent.\n",
    "\n",
    "Make sure to label each axis, and each series (training vs.¬†validation/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot the training and validation accuracy in one plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation loss values saved in the `hist.history` dictionary, on the same plot. You should see that the training loss is steadily decreasing. Use the [`semilogy` plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.semilogy.html) so that the y-axis is log scale.\n",
    "\n",
    "Make sure to label each axis, and each series (training vs.¬†validation/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot the training and validation loss in one plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the Learning Rate\n",
    "-------------------------\n",
    "\n",
    "One challenge in training neural networks is the selection of the learning rate. Repeat your model preparation and fitting code, but try four learning rates as shown in the vector `rates`. In each iteration of the loop:\n",
    "\n",
    "-   use `K.clear_session()` to free up memory from models that are no longer in scope\n",
    "-   construct the network\n",
    "-   select the optimizer. Use the Adam optimizer with the learning rate specific to this iteration\n",
    "-   train the model for 20 epochs\n",
    "-   save the history of training and validation accuracy and loss for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates = [0.1, 0.01,0.001,0.0001]\n",
    "\n",
    "# TODO - iterate over learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss vs.¬†the epoch number for all of the learning rates on one graph (use `semilogy` again). You should see that the lower learning rates are more stable, but converge slower, while with a learning rate that is too high, the gradient descent may fail to move towards weights that decrease the loss function.\n",
    "\n",
    "Make sure to label each axis, and each series.\n",
    "\n",
    "**Comment on the results.** What is the effect of learning rate on the training process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot showing the training process for different learning rates"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "colab": ""
 }
}
